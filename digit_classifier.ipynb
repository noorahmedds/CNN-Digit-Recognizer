{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import scipy\n",
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "X_train = pd.read_csv('input/trainData.csv')\n",
    "y_train = pd.read_csv('input/trainLabels.csv')\n",
    "X_test = pd.read_csv('input/kaggleTestSubset.csv')\n",
    "y_test = pd.read_csv('input/kaggleTestSubsetLabels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "models.append(MLPClassifier(activation=\"relu\", solver = \"adam\", alpha=1e-5, hidden_layer_sizes=(700, 500, 250, 100), random_state=1, learning_rate=\"invscaling\", warm_start=True))\n",
    "models.append(MLPClassifier(activation=\"tanh\", solver = \"adam\", alpha=1e-5, hidden_layer_sizes=(700, 500, 250, 100), random_state=1, learning_rate=\"invscaling\", warm_start=True))\n",
    "models.append(MLPClassifier(activation=\"logistic\", solver = \"adam\", alpha=1e-5, hidden_layer_sizes=(700, 500, 250, 100), random_state=1, learning_rate=\"invscaling\", warm_start=True))\n",
    "models.append(MLPClassifier(activation=\"relu\", solver = \"sgd\", alpha=1e-5, hidden_layer_sizes=(700, 500, 250, 100), random_state=1, learning_rate=\"invscaling\", warm_start=True))\n",
    "models.append(MLPClassifier(activation=\"tanh\", solver = \"sgd\", alpha=1e-5, hidden_layer_sizes=(700, 500, 250, 100), random_state=1, learning_rate=\"invscaling\", warm_start=True))\n",
    "models.append(MLPClassifier(activation=\"logistic\", solver = \"sgd\", alpha=1e-5, hidden_layer_sizes=(700, 500, 250, 100), random_state=1, learning_rate=\"invscaling\", warm_start=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(m):\n",
    "    fit_time = time.time()\n",
    "    m.fit(X_train, y_train.Label)\n",
    "    fit_time = time.time() - fit_time\n",
    "\n",
    "    pred_time = time.time()\n",
    "    pred = m.predict(X_test)\n",
    "    pred_time = time.time() - pred_time\n",
    "    \n",
    "    acc = accuracy_score(y_test, pred)\n",
    "    print(\"Accuracy: \" + str(acc) + \" Time to train: \" + str(fit_time) + \" Time to predict:\" + str(pred_time))\n",
    "    print (\"=====================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.985242718447 Time to train: 39.448906898498535 Time to predict:0.14255380630493164\n",
      "=====================\n",
      "Accuracy: 0.985242718447 Time to train: 52.28204798698425 Time to predict:0.1663961410522461\n",
      "=====================\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    test_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'relu'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage import interpolation\n",
    "\n",
    "def moments(image):\n",
    "    c0,c1 = np.mgrid[:image.shape[0],:image.shape[1]] # A trick in numPy to create a mesh grid\n",
    "    totalImage = np.sum(image) #sum of pixels\n",
    "    m0 = np.sum(c0*image)/totalImage #mu_x\n",
    "    m1 = np.sum(c1*image)/totalImage #mu_y\n",
    "    m00 = np.sum((c0-m0)**2*image)/totalImage #var(x)\n",
    "    m11 = np.sum((c1-m1)**2*image)/totalImage #var(y)\n",
    "    m01 = np.sum((c0-m0)*(c1-m1)*image)/totalImage #covariance(x,y)\n",
    "    mu_vector = np.array([m0,m1]) # Notice that these are \\mu_x, \\mu_y respectively\n",
    "    covariance_matrix = np.array([[m00,m01],[m01,m11]]) # Do you see a similarity between the covariance matrix\n",
    "    return mu_vector, covariance_matrix\n",
    "\n",
    "def deskew(image):\n",
    "    c,v = moments(image)\n",
    "    alpha = v[0,1]/v[0,0]\n",
    "    affine = np.array([[1,0],[alpha,1]])\n",
    "    ocenter = np.array(image.shape)/2.0\n",
    "    offset = c-np.dot(affine,ocenter)\n",
    "    return interpolation.affine_transform(image,affine,offset=offset)\n",
    "\n",
    "def preprocess_X(X):\n",
    "    result = []\n",
    "    values = X.values\n",
    "    for v in values:\n",
    "        curr = v.reshape((28, 28))\n",
    "        curr = deskew(curr)\n",
    "        result.append(curr.flatten())\n",
    "        \n",
    "    return result\n",
    "\n",
    "\n",
    "deskewed_train = preprocess_X(X_train/255)\n",
    "deskewed_test = preprocess_X(X_test/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(700, 500, 250, 100), learning_rate='invscaling',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
       "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "       warm_start=True)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(deskewed_train, y_train.Label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99300970873786409"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, model.predict(deskewed_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read data\n",
    "X_test_full = pd.read_csv('input/testData.csv')\n",
    "deskewed_test = preprocess_X(X_test_full/255)\n",
    "predictions = model.predict(deskewed_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('submission1.csv', 'w') as file:\n",
    "    fieldnames = ['ID', 'Label']\n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "    \n",
    "    writer.writeheader()\n",
    "    i = 1\n",
    "    for prediction in predictions:\n",
    "        writer.writerow({'ID':i, 'Label':prediction})\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder = OneHotEncoder()\n",
    "labels = encoder.fit_transform(y_train)\n",
    "labels_test = encoder.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# this applies 32 convolution filters of size 3x3 each.\n",
    "model.add(Conv2D(100, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(Conv2D(50, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(4, 4)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "# model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(600, activation='relu'))\n",
    "model.add(Dense(400, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "adam = Adam()\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_im = X_train.values.reshape(len(X_train.values), 28, 28, 1)\n",
    "X_test_im = X_test.values.reshape(len(X_test.values), 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12019/12019 [==============================] - 80s 7ms/step - loss: 6.6509 - acc: 0.5769\n",
      "Epoch 2/10\n",
      "12019/12019 [==============================] - 84s 7ms/step - loss: 1.9929 - acc: 0.8623\n",
      "Epoch 3/10\n",
      "12019/12019 [==============================] - 84s 7ms/step - loss: 0.1190 - acc: 0.9814\n",
      "Epoch 4/10\n",
      "12019/12019 [==============================] - 81s 7ms/step - loss: 0.0410 - acc: 0.9897\n",
      "Epoch 5/10\n",
      "12019/12019 [==============================] - 78s 7ms/step - loss: 0.0226 - acc: 0.9929\n",
      "Epoch 6/10\n",
      "12019/12019 [==============================] - 79s 7ms/step - loss: 0.0173 - acc: 0.9951\n",
      "Epoch 7/10\n",
      "12019/12019 [==============================] - 79s 7ms/step - loss: 0.0126 - acc: 0.9964\n",
      "Epoch 8/10\n",
      "12019/12019 [==============================] - 79s 7ms/step - loss: 0.0138 - acc: 0.9953\n",
      "Epoch 9/10\n",
      "12019/12019 [==============================] - 78s 7ms/step - loss: 0.0108 - acc: 0.9969\n",
      "Epoch 10/10\n",
      "12019/12019 [==============================] - 78s 7ms/step - loss: 0.0069 - acc: 0.9979\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11cea2978>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_im, labels, batch_size=100, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2575/2575 [==============================] - 6s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.019671346874156635, 0.99533980582524273]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_im, labels_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
